return {
  -- {
  --   "zbirenbaum/copilot.lua",
  --   cmd = "Copilot",
  --   build = ":Copilot auth",
  --   opts = {
  --     suggestion = { enabled = false },
  --     panel = { enabled = false },
  --     filetypes = {
  --       markdown = true,
  --       help = true,
  --     },
  --   },
  -- },
  -- {
  --   "olimorris/codecompanion.nvim",
  --   dependencies = {
  --     "nvim-lua/plenary.nvim",
  --     "nvim-treesitter/nvim-treesitter",
  --     "hrsh7th/nvim-cmp",
  --     "nvim-telescope/telescope.nvim",
  --     { "stevearc/dressing.nvim", opts = {} },
  --   },
  --   config = function()
  --     require("codecompanion").setup({
  --       strategies = {
  --         chat = {
  --           adapter = "ollama",
  --         },
  --         inline = {
  --           adapter = "ollama",
  --         },
  --         agent = {
  --           adapter = "ollama",
  --         },
  --       },
  --     })
  --   end,
  -- },
  -- {
  --   "David-Kunz/gen.nvim",
  --   config = function()
  --     require("gen").setup({
  --       model = "llama3.2",
  --       quit_map = "q",
  --       retry_map = "<c-r>",
  --       accept_map = "<c-cr>",
  --       display_mode = "split", -- The display mode. Can be "float" or "split" or "horizontal-split".
  --       show_prompt = true,
  --       show_model = true,
  --       no_auto_close = false, -- Never closes the window automatically.
  --       hidden = false, -- Hide the generation window (if true, will implicitly set `prompt.replace = true`), requires Neovim >= 0.10
  --       init = function(options)
  --         pcall(io.popen, "ollama serve > /dev/null 2>&1 &")
  --       end,
  --       -- Function to initialize Ollama
  --       command = function(options)
  --         local body = { model = options.model, stream = true }
  --         return "curl --silent --no-buffer -X POST http://"
  --           .. options.host
  --           .. ":"
  --           .. options.port
  --           .. "/api/chat -d $body"
  --       end,
  --     })
  --
  --     vim.keymap.set({ "n", "v" }, "<leader>a", "<cmd>Gen<CR>", { desc = "AI Prompt selection" })
  --   end,
  -- },
}
